---
title: "Development on remote container with VSCode"
permalink: /docker-with-gpu/
author_profile: true
date: "2020-08-22T00:00:00-05:00"
# image: assets/posts/hello_world/steven-houston-d2lO9btumD4-unsplash.jpg
classes: wide
header:
  teaser: /assets/posts/docker-with-gpu/nvidia-docker-banner.png
#   overlay_color: "#000"
#   overlay_filter: "0.5"
  overlay_image: /assets/posts/hello_world/steven-houston-d2lO9btumD4-unsplash.jpg
  caption: "Photo by [**Steven Houston**](https://unsplash.com/@stevenhoustonfit?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText) on [**Unsplash**](https://unsplash.com/s/photos/writing-in-the-dark?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText)"
excerpt: "Create an isolated deep learning environment (GPU) with Docker and VSCode."
---

I really like Docker and try to overwhelmingly use for my daily stuff. It provides the best isolation and reproducibility in my working environment. For example, one particular use case of mine is developing my deep learning model on my personal rig in the office, and then easily deploying it on the university's cluster nodes to make parallel experiments. I don't get any headache for dependency issues, let alone eliminating the hassle of building the same environment on 8 or what machines.

TBC. 
